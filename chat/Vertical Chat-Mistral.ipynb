{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/Large-Language-Model-Notebooks-Course/blob/main/1-Introduction%20to%20LLMs%20with%20OpenAI/Vertical%20Chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zwzWskLgXgj5",
      "metadata": {
        "id": "zwzWskLgXgj5"
      },
      "source": [
        "<div align=\"center\">\n",
        "<h1><a href=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course\">Learn by Doing LLM Projects</a></h1>\n",
        "    <h3>Understand And Apply Large Language Models</h3>\n",
        "    <h2>Create your first ChatBot with OpenAI</h2>\n",
        "    <h3>Using GPT 3.5, Python and Panel</h3>\n",
        "    by <b>Pere Martra</b>\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<div align=\"center\">\n",
        "    &nbsp;\n",
        "    <a target=\"_blank\" href=\"https://www.linkedin.com/in/pere-martra/\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>\n",
        "    \n",
        "</div>\n",
        "\n",
        "<br>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c23b4dd1",
      "metadata": {
        "id": "c23b4dd1"
      },
      "source": [
        "# Vertical Chat\n",
        "A sample how to build a chat for small businees using:\n",
        "\n",
        "* GPT 35\n",
        "* Panel\n",
        "* OpenAI\n",
        "\n",
        "\n",
        "This is just a simple sample to start to understand how the OpenAI API works, and how to create Prompts. It Is really far from beign a complete solution.\n",
        "We are going to introduce some interesting points:\n",
        "\n",
        "* The roles in a conversation.\n",
        "* How is the conversations’ memory preserved?\n",
        "\n",
        "Deeper explanations in the article: [Create Your First Chatbot Using GPT 3.5, OpenAI, Python and Panel.](https://medium.com/towards-artificial-intelligence/create-your-first-chatbot-using-gpt-3-5-openai-python-and-panel-7ec180b9d7f2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1d00720",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1d00720",
        "outputId": "507ec869-bd20-4837-e731-4188221494dd"
      },
      "outputs": [],
      "source": [
        "#First install the necessary libraries\n",
        "# !pip install openai==1.1.1\n",
        "# !pip install panel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a03f026a",
      "metadata": {
        "id": "a03f026a"
      },
      "outputs": [],
      "source": [
        "#if you need an API Key from OpenAI\n",
        "#https://platform.openai.com/account/api-keys\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "device = \"cpu\" # the device to load the model onto\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "import panel as pn\n",
        "\n",
        "# #from mykeys import openai_api_key\n",
        "# openai.api_key=\"your-api-key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77eac86d",
      "metadata": {
        "id": "77eac86d"
      },
      "outputs": [],
      "source": [
        "def continue_conversation(tokenizer, messages, temperature=0):\n",
        "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "    generated_ids = model.generate(messages, max_new_tokens=1000, do_sample=True)\n",
        "    decoded = tokenizer.batch_decode(generated_ids)\n",
        "    return(decoded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51bec475",
      "metadata": {
        "id": "51bec475"
      },
      "outputs": [],
      "source": [
        "def add_prompts_conversation(_):\n",
        "    #Get the value introduced by the user\n",
        "    prompt = client_prompt.value_input\n",
        "    client_prompt.value = ''\n",
        "\n",
        "    #Append to the context the User prompt.\n",
        "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
        "\n",
        "    #Get the response.\n",
        "    response = continue_conversation(tokenizer,messages=context)\n",
        "\n",
        "    #Add the response to the context.\n",
        "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
        "\n",
        "    #Update the panels to show the conversation.\n",
        "    panels.append(\n",
        "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600)))\n",
        "\n",
        "    return pn.Column(*panels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "922f8d24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "922f8d24",
        "outputId": "93183987-3b29-4430-d8cc-6d6453a98574"
      },
      "outputs": [],
      "source": [
        "#Creating the prompt\n",
        "#read and understand it.\n",
        "context = [ {'role':'system', 'content':\"\"\"\n",
        "Act as an OrderBot, you work collecting orders in a delivery only fast food restaurant called\n",
        "My Dear Frankfurt. \\\n",
        "First welcome the customer, in a very friendly way, then collects the order. \\\n",
        "You wait to collect the entire order, beverages included \\\n",
        "then summarize it and check for a final \\\n",
        "time if everything is ok or the customer wants to add anything else. \\\n",
        "Finally you collect the payment.\\\n",
        "Make sure to clarify all options, extras and sizes to uniquely \\\n",
        "identify the item from the menu.\\\n",
        "You respond in a short, very friendly style. \\\n",
        "The menu includes \\\n",
        "burger  12.95, 10.00, 7.00 \\\n",
        "frankfurt   10.95, 9.25, 6.50 \\\n",
        "sandwich   11.95, 9.75, 6.75 \\\n",
        "fries 4.50, 3.50 \\\n",
        "salad 7.25 \\\n",
        "Toppings: \\\n",
        "extra cheese 2.00, \\\n",
        "mushrooms 1.50 \\\n",
        "martra sausage 3.00 \\\n",
        "canadian bacon 3.50 \\\n",
        "romesco sauce 1.50 \\\n",
        "peppers 1.00 \\\n",
        "Drinks: \\\n",
        "coke 3.00, 2.00, 1.00 \\\n",
        "sprite 3.00, 2.00, 1.00 \\\n",
        "vichy catalan 5.00 \\\n",
        "\"\"\"} ]\n",
        "\n",
        "#Creating the panel.\n",
        "pn.extension()\n",
        "\n",
        "panels = []\n",
        "\n",
        "client_prompt = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\n",
        "button_conversation = pn.widgets.Button(name=\"talk\")\n",
        "\n",
        "interactive_conversation = pn.bind(add_prompts_conversation, button_conversation)\n",
        "\n",
        "dashboard = pn.Column(\n",
        "    client_prompt,\n",
        "    pn.Row(button_conversation),\n",
        "    pn.panel(interactive_conversation, loading_indicator=True),\n",
        ")\n",
        "\n",
        "dashboard"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
